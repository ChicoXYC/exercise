{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for n in range(1, 5):\n",
    "    link = \"https://xkcd.com/\"+str(n)+\"/\"\n",
    "    link = \"https://xkcd.com/\"+ \"page=\"+str(n)\n",
    "    print(link)\n",
    "\n",
    "    response = requests.get(link)\n",
    "    page = BeautifulSoup(response.text, features=\"lxml\")\n",
    "\n",
    "    image_elements = page.select(\"#comic > img\")\n",
    "    image_elements = \n",
    "    src = image_elements[0]['src']\n",
    "\n",
    "    image_link = \"http:\"+src\n",
    "    print(image_link)\n",
    "\n",
    "    image_response = requests.get(image_link)\n",
    "\n",
    "    print(\"write file \"+str(n)+\".jpg\")\n",
    "    with open(str(n)+\".jpg\", \"wb\") as f:\n",
    "        f.write(image_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://xkcd.com/1/\"\n",
    "response = requests.get(link)\n",
    "data = BeautifulSoup(response.text, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = data.find('div',attrs={'id':'ctitle'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('123.csv','w') as f:\n",
    "    f.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,6):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = [1,2,3,4,5]\n",
    "for element in number_list:\n",
    "    print (element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get('http://www.court.gov.cn/paper/default/index/keyword/%E7%9F%A5%E8%AF%86%E4%BA%A7%E6%9D%83/caseid//starttime//stoptime.html') \n",
    "html_str = resp.text\n",
    "document = BeautifulSoup(html_str,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = document.find_all('li',attrs={'class':'wslist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = articles[0].find('li',attrs={'class':'list_tit'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = articles[0].find('div',attrs={'class':'date'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_number = articles[0].find('div',attrs={'class':'ah'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "for article in articles:\n",
    "    element={}\n",
    "    element['title'] = article.find('li',attrs={'class':'list_tit'}).text\n",
    "    element['time'] = article.find('div',attrs={'class':'date'}).text\n",
    "    element['case_number'] = article.find('div',attrs={'class':'ah'}).text\n",
    "    info.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Court Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_url = 'http://www.court.gov.cn/paper/default/index/keyword/知识产权/caseid//starttime//stoptime.html'\n",
    "\n",
    "all_info = []\n",
    "for i in range(0,36):\n",
    "    url = 'http://www.court.gov.cn/paper/default/index/keyword/知识产权/caseid//starttime//stoptime/page/23//page/'+str(i+1)+'.html'\n",
    "    print(url)\n",
    "    resp = requests.get(url) \n",
    "    html_str = resp.text\n",
    "    document = BeautifulSoup(html_str,'html.parser')\n",
    "    articles = document.find_all('li',attrs={'class':'wslist'})\n",
    "    info = []\n",
    "    for article in articles:\n",
    "        element={}\n",
    "        element['title'] = article.find('li',attrs={'class':'list_tit'}).text\n",
    "        element['time'] = article.find('div',attrs={'class':'date'}).text\n",
    "        element['case_number'] = article.find('div',attrs={'class':'ah'}).text\n",
    "        info.append(element)\n",
    "    all_info.extend(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('case.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('case.txt','w') as f:\n",
    "    my_writer = csv.writer(f)\n",
    "    for title in df['title']:\n",
    "        my_writer.writerow([title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "text = open('case.txt',\"r\").read()\n",
    "#cut words\n",
    "words = jieba.cut(text)\n",
    "#set stopwords\n",
    "filepath = 'stopwords.txt'\n",
    "stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "#remove stopwords\n",
    "processed_word_list = []\n",
    "for word in words:\n",
    "    if word not in stopwords and len(word)>1: #remove single word\n",
    "        processed_word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(processed_word_list)\n",
    "df = df.rename(columns={0:'words'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['words'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=df2['index'][:100]\n",
    "words = words.tolist()\n",
    "value=df2['words'][:100]\n",
    "value = value.tolist()\n",
    "from pyecharts import WordCloud\n",
    "word = words\n",
    "value = value\n",
    "wordcloud = WordCloud(width=1300, height=620)\n",
    "wordcloud.add(\"\", word, value, word_size_range=[20, 100])\n",
    "wordcloud.render('case-wordcloud.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
